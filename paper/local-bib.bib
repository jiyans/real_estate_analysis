@incollection{NEURIPS2019_9015,
  author          = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer,
                  Adam and Bradbury, James and Chanan, Gregory and Killeen,
                  Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga,
                  Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward
                  and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and
                  Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai,
                  Junjie and Chintala, Soumith},
  year            = 2019,
  booktitle       = {Advances in Neural Information Processing Systems 32},
  editor          = {H. Wallach and H. Larochelle and A. Beygelzimer and F.
                  d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
  pages           = {8024--8035},
  publisher       = {Curran Associates, Inc.},
  title           = {PyTorch: An Imperative Style, High-Performance Deep
                  Learning Library},
}

@incollection{NIPS2017_7062,
  title           = {A Unified Approach to Interpreting Model Predictions},
  author          = {Lundberg, Scott M and Lee, Su-In},
  booktitle       = {Advances in Neural Information Processing Systems 30},
  editor          = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and
                  R. Fergus and S. Vishwanathan and R. Garnett},
  pages           = {4765--4774},
  year            = 2017,
  publisher       = {Curran Associates, Inc.},
}

@article{akiyamayuki2019230204,
  _author         = {{Akiyama Yuki 秋山 祐樹}},
  author          = {Akiyama, Yuki},
  doi             = {10.11353/sesj.32.53},
  journal         = {環境科学会誌},
  number          = 2,
  pages           = {53-64},
  title           = {マイクロジオデータを用いた日本全国の家賃形成メカニズムの研
                  究---住環境と住宅の市場価値の意外な関係性---},
  volume          = 32,
  year            = 2019,
}

@article{choi2003,
  _author         = {{Choi Jung Min 崔廷敏 and Asami Yasushi 浅見泰司}},
  author          = {Choi, J. M. and Asami, Y.},
  doi             = {10.11531/uhs1993.2003.42_86},
  issn            = {1341-8157},
  journal         = {都市住宅学},
  number          = 42,
  pages           = {86-97},
  publisher       = {公益社団法人 都市住宅学会},
  title           = {賃貸住宅居住者の満足度評価に見られる潜在的評価構造},
  volume          = 2003,
  year            = 2003,
}

@online{he15:deep_resid_learn_image_recog,
  archiveprefix   = {arXiv},
  author          = {Kaiming He AND Xiangyu Zhang AND Shaoqing Ren AND Jian Sun},
  eprint          = {1512.03385v1},
  primaryclas     = {cs.CV},
  title           = {{Deep Residual Learning for Image Recognition}},
  year            = 2015
}

@article{howard20_fastai,
  abstract        = {fastai is a deep learning library which provides
                  practitioners with high-level components that can quickly and
                  easily provide state-of-the-art results in standard deep
                  learning domains, and provides researchers with low-level
                  components that can be mixed and matched to build new
                  approaches. It aims to do both things without substantial
                  compromises in ease of use, flexibility, or performance. This
                  is possible thanks to a carefully layered architecture, which
                  expresses common underlying patterns of many deep learning and
                  data processing techniques in terms of decoupled abstractions.
                  These abstractions can be expressed concisely and clearly by
                  leveraging the dynamism of the underlying Python language and
                  the flexibility of the PyTorch library. fastai includes: a new
                  type dispatch system for Python along with a semantic type
                  hierarchy for tensors; a GPU-optimized computer vision library
                  which can be extended in pure Python; an optimizer which
                  refactors out the common functionality of modern optimizers
                  into two basic pieces, allowing optimization algorithms to be
                  implemented in 4-5 lines of code; a novel 2-way callback
                  system that can access any part of the data, model, or
                  optimizer and change it at any point during training; a new
                  data block API; and much more. We have used this library to
                  successfully create a complete deep learning course, which we
                  were able to write more quickly than using previous
                  approaches, and the code was more clear. The library is
                  already in wide use in research, industry, and teaching. NB:
                  This paper covers fastai v2, which is currently in pre-release
                  at http://dev.fast.ai/},
  archiveprefix   = {arXiv},
  author          = {Howard, Jeremy and Gugger, Sylvain},
  eprint          = {2002.04688},
  journal         = {CoRR},
  primaryclass    = {cs.LG},
  title           = {Fastai: a Layered Api for Deep Learning},
  year            = 2020,
}

@inproceedings{imagenet2009,
  author          = {Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia
                  and Kai Li and Li Fei-Fei},
  booktitle       = {2009 IEEE Conference on Computer Vision and Pattern
                  Recognition},
  doi             = {10.1109/CVPR.2009.5206848},
  pages           = {248-255},
  title           = {ImageNet: A large-scale hierarchical image database},
  year            = 2009,
}

@misc{kingma2017adam,
  title           = {Adam: A Method for Stochastic Optimization},
  author          = {Diederik P. Kingma and Jimmy Ba},
  year            = 2017,
  eprint          = {1412.6980},
  archivePrefix   = {arXiv},
  primaryClass    = {cs.LG}
}

@misc{smith17_cyclic_learn_rates_train_neural_networ,
  archiveprefix   = {arXiv},
  author          = {Leslie N. Smith},
  date_added      = {Wed Dec 29 13:05:14 2021},
  eprint          = {1506.01186},
  primaryclass    = {cs.CV},
  title           = {Cyclical Learning Rates for Training Neural Networks},
  year            = 2017
}
