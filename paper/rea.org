#+title: WIP Using Deep Learning to Assist Modelling of Tokyo Real Estate Prices
#+SUBTITLE: WIP An evaluation of an incorporation of deep learning methods for prediction real estate prices
#+AUTHOR: Jiyan Jonas Schneider
#+DATE: 2021-12-20
#+LATEX_HEADER: \usepackage{xeCJK}
#+BIBLIOGRAPHY: /Users/jiyanschneider/Dropbox/Documents/lib/bibliography/bibliography.bib
#+LATEX_HEADER: \setCJKmainfont{HiraginoSans-W3}
#+LATEX_HEADER: \usepackage[backend=biber, style=apa]{biblatex}
#+LATEX_HEADER: \setmainfont{EBGaramond-Regular}
#+LATEX_HEADER: \usepackage[a4paper,left=2.5cm,right=2.5cm,top=2.5cm,bottom=2.5cm]{geometry}
#+LATEX_HEADER: \usepackage{graphics}
#+LATEX_HEADER: \usepackage[doublespacing]{setspace}
#+LATEX_CLASS_OPTIONS: [12pt,titlepage]
#+OPTIONS: toc:2 H:4


#+begin_abstract
This study strives to examine the structure of real estate rental prices,
taking into account the property's layout. We find that when using computer
vision methods to analyze the apartment rent
the viability of using Deep Learning methods and what they might have in
housing. There have been studies investigating the use of Machine
Learning methods for this kind of task. The novelty in our study primarily lies
in the use of Computer Vision Deep Learning methods to analyze the images of the
floorplans to assist with prediction. By making use of one of the computer
vision models described in [cite:@park2015using] to create an attractiveness
measure based solely on the floorplan, we can improve a regular hedonic
pricing model from an $R^{2}$ of 0.915 to an $R^{2}$ of 0.945. This suggests
that floorplans contain considerable information about rent prices
and thus consumer behavior, which is not usually covered in hedonic
regressions.
#+end_abstract

* Introduction

The problem of real estate value estimation comes up in multiple forms
throughout economics and society, with many kinds of agents being interested in
predicting housing and real estate prices. Appraisers and tax assessors conduct
real-estate appraisals, investors conduct fundamental value analyses
[cite:@krainer2004], and it is reasonable to assume that other parties such as
banks have methods of assessing the price of a property as well, for their
mortgage lending operations. The real estate appraisal done by appraisers and
tax assesors is often done on an individual basis, appraisal might be done
individually, with nationally certified appraisers estimating the value of a
house.

However, in most other contexts that are on a larger scale, real-estate prices
ahve to be estimated with more quantitative methods. For example, the potential
rent that a property would receive on the market at a given time has to be
estimated or imputed to determine certain economic variables such as the GDP. In
economics, real estate prices are often considered hedonic prices, meaning that
the final price of a good is determined by the parts that make it up, and
hedonic methods are often the de facto methods for real estate price estimation.

These methods, however, do not readily incorporate information about the real-estate
properties at the apartment level, as this kind of information is hard to obtain and formulate.
Most previous research uses tabular data for price estimation, and detailed information
on for example apartment-level is not available. Such features might include the size
of the kitchen, or the bathtub. However, such information would be expected to have
an effect on real-estate prices as well.

The underlying hypothesis of this research paper is that the floorplans expose
some characteristics that are valuable to consumers, negelcted with traditional
methods, and can be leveraged with Deep Learning. In the long run, we hope to
advance insight into the price structure of real estate and consumer behavior
surrounding real estate.

To test our hypothesis we first collected tabular data and floorplans of over
100,000 rental apartments in the Tokyo Metropolitan area from a publicly
available website. Then we devised some small changes to a widely used neural
network architecture, and trained a neural network (NN herafter) to predict the
rent of an apartment given only its floorplan. Finally, we combined the NN's
prediction with a traditional hedonic regression model, and analyze the effects
including the NN's predictions has.

Doing this, we find that the Neural network is able to explain a large
proportion of the rent price of many properties and considerably improve the
explanatory power of the hedonic regression model. Furthermore, we find that the
effects including our predictions in the hedonic regression model has are
stable. Including the Neural Network does not overly take away explanatory power
from variables that would be considered important in a more traditional model or
affect the other variables in other unexected ways, showing that the Neural Network
captures at least some previously unconsidered factors.

The structure of the remaining paper is as follows: First we will introduce to
the reader some background about the topic of real estate prices. After that we
will describe the dataset we used and under which circumstances it was built.
After that we will explain the architecture of the Neural Network used in
detail, and explain a bit about how we integrated it with the existing
methodology. After explaining the models, we will present the results, and conclude
with a discussion about the implications and limitations about this study.

* Background
** Machine Learning methods in real estate
Some previous research of using Machine learning methods for real estate data
has been conducted. For example, [cite:@hattori2019rent] uses Principal
Component Analysis to extract a feature vector from floorplan data and
subsequently uses this vector in various models. However, they report that while
there are slight improvements in prediction, it is challenging to find merits
for using their approach because these improvements are too small.

Furthermore, [cite:@zeng2019deep] use a computer vision on floorplan images.
However, they are looking to find out functionalities of different elements
within the floorplan rather than using it for rent prediction. The earliest
example of the use of Neural Networks for rent price prediction we could find
was [cite:@limsombunchai2004], in which they already argue for the use of Neural
Networks in real-estate price predictions over hedonic methods in spite of the
trouble of interpreting Neural Networks, simply due to their increased
predictive powers.

As real-estate prices have to be estimated in various situations, with varying
amounts of granularity in data, and with differing objectives, they are often
criticized from various perspectives. For example, mortgage lenders might be
more willing to obtain more data, in order to get more accurate predictions,
than governments, who want to estimate rents home-owners would receive for
properties on the market market. These estimates would then be used for
inclusion in economic variables such as the Gross domestic product, or in
government statistics. Due to these different kinds of uses, different kinds of
criticisms are offered, for exmaple [cite:@weko_55303_1] criticizes imputation
methods the japanese government is using for being too simplistic. They argue
that the locations of properties should be considered on a finer level, and
that city planning and housing quality should be considered as well.

An attempt to use computer vision for the estimation was made in
[cite:@poursaeed2018]. They use pictures of exteriors and interiors of
properties to improve price predictions. They have success with their approach,
and improve on the base model they are using. Their research differs with ours,
in that they are not making use of the actual floorplans of the estates. Their
approach certainly seems valuable especially for parties that have access to
pictures of the interiours of the apartments. However floorplans contain
information of characteristics that are intrinsic to their real estate property,
while pictures of interiors carry with them much subjectivity. When analyzing
photographs, the quality, lighting, angles, and interior furniture would be
expected to affect the evaluation of a property. Floorplans, however, especially
when prepared professionally, include information inherent to a specific estate,
for example, the sizes of the different rooms and their relative location to
each other. Overall, most research conducted makes use of cross-sectional data.
[cite:@akiyama_yuki2019320204;@weko_55303_1;@limsombunchai2004]

** Price structure of real estate
Moving onto the price structure of real-estate, [cite:@krainer2004] note, using
time-series data, that house price and rent price, while related, are not the
same, and identify the change in price-rent ratio between the year from 1982
to 2002. Determining the price structure of real-estate in general is more
complicated than doing a regular regression, as noted in
[cite:@rosen_1974_hedonic] and [cite:@nelson1978]. Most studies in the
literature starting from [cite:@nelson1978], assume that factors for real-estate
prices can mostly be divided into two categories, the physical characteristics
of the propertie, and the environmental properties. The physical, sometimes also
called structural, influences about the properties, might be its size, the
number of rooms, or its layout size. On the other hand, the environmental
factors are not directly included in the apartment but are related to the
environment of the properties' location. Examples would be the distance to the
closest schools, the city center, or the nearest train station. Both, the
structural and environmental factors might change depending on the market, as
different markets tend to have their peculiarities. For example, in big Japanese
cities, people spend a higher proportion of their income on rent and tend to put
a higher relative value on property location than in other places.
[cite:@salarymen1999]

The imporance of greater subdivision of markets is a topic that often comes up
in the discussion about real-estate price estimation, and is dealt with in
different ways. An example of for an advanced method of subdivision of markets
is [cite:@akiyama_yuki2019320204]. They use a vast dataset containing
information of buildings throughout all of Japan. They rely on the K-Means++
algorithm to create clusters and use the Gap statistic to determine the optimal
amount of clusters to use. In their subsequent analysis, they use these clusters to
analyze their data on a by-market basis.

Lastly, [cite:@choi2003], a study about the causes of residential satisfaction
conducted through a survey, finds that the above two categories of "structural"
and "enviornmental", can be further subdivided. A unique quality this study has,
is that it considers real estate prices not only econometrically, but also tries
to understand their users' psychology in more detail. Their study asks its
participants to list their satisfaction levels about their current apartment. In
total, they list 35 items. These items are originally subdivided into the two
categories mentioned earlier: "Structural" and "Enviornmental". While conducting
their analysis they obtain results of how much each of the 35 items influences
overall residential satisfaction. Furthermore, they establish that the above two
categories could be further subclassified. Roughly, they subdivide the items in
the "Structural" category further into "Fundamentals (基礎環境)[fn:2]" and "Size
and Facilities(広さ・設備)". In table [[tab:satisfaction_items]], we show the items
that the survey participants were asked about. All of these items are items from
the "Structural" category, were further subdivided into the categories shown.
Their study also shows that these two categories, have the most impact on the
residential satisfaction, and in particular have a larger impact on satisfaction
than the environmental factors.
#+LABEL: tab:satisfaction_items
#+NAME: tab:satisfaction_items
#+ATTR_LATEX: :name tab:satisfaction_items :label tab:satisfaction_items
#+CAPTION: Table describing the groups and items participants were asked to judge their satisfaction by,  in [cite:@choi2003].
| Fundamental           | Size and Facilities        |
|-----------------------+----------------------------|
| Lighting              | Overall Size               |
| Ventilation           | Floorplan                  |
| Condensation (or dew) | number of rooms            |
| Insulation            | Interior design and Finish |
| Noise                 | Storage space              |
| Outward appearance    | Kitchen space              |
|                       | Kitchen facilities         |
|                       | Washing room space         |
|                       | Washing room facilities    |
|                       | Bathtub size               |
This is a conclusion that is shared by [cite:@akiyama_yuki2019320204], who find
that structural characteristics are generally preferred over environmental
features, even in Tokyo, where environmental features are regularly valued more
highly than in other parts of Japan. They also come to the interesting
conclusion that the security places seems to be left mostly unconsidered by most
people when choosing where to live.

We believe, that while structural features seem to be more impactful, they are
also harder to obtain. Although apartment size, is a standard characteristic
available in most datasets, more specific features like washing room space, or
kitchen space are harder acquire. However, many of the structural features are
available in floorplan information. For example, while about residential
satisfaction and not explicitly about rent prices, we believe that floorplans
contain information about all features in the "Size and Facilities" section.
Furthermore, many floorplans even contain information about balconies, the
information about the windows, the cardinal direction of the apartment, and some
even include the placement of air conditioning machines. This information could
be helpful in determining some of the "Fundamentals" as well.

Lastly, floorplans also expose information about more complicated notions that
were not asked in [cite:@choi2003], possibly because they are complicated.
Examples of this could be the proportions of rooms relative to each other, the
location of the shower and the toilet (are they in the same room), or working
space in the kitchen.

* Models, Methods, Architecture
** Data
The dataset used is a mix of tabular and image data of rental real estate
properties from the Tokyo Metropolitan area listed on a public website. The
data was collected to write this paper.

We focused on rental apartments in Tokyo in particular because, as outlined in
[cite:@weko_55303_1,@moriizumi1986] and [cite:@akiyama_yuki2019320204],
estimating real estate prices estimated throughout different markets is more
challenging and causes complications as described earlier. This is an
exploratory study, so we decided that by focusing on "roughly" a single market, we
can sidestep this problem and focus on the viability of these computer vision
methods first.

For each listing, we have the monthly rent of the apartment, the image of the
floorplan of the apartment, 6 continuous and 3 categorical variables. The
details for the tabular variables are described in Table [[tab:var_explanation]].
#+LABEL: tab:var_explanation
#+NAME: tab:var_explanation
#+CAPTION: Explanation of the variables collected and used in this study.
#+ATTR_LATEX: :name tab:var_explanation :label tab:var_explanation
|-----------------+---------------------------------------------------------------|
| Variable        | Explanation                                                   |
|-----------------+---------------------------------------------------------------|
|-----------------+---------------------------------------------------------------|
| Floor           | The floor the property is on property                         |
| Size            | Size of property in $m^2$                                     |
| Time to station | No. minutes of taking "method" to the next station            |
| Age bldg.       | No. of years ago the property was built                       |
| Floors bldg     | No of floors of the building                                  |
| Admin fee       | Amount of monthly administration fee                          |
|-----------------+---------------------------------------------------------------|
| Station         | Name of the closest public transport station                  |
| Method          | How "Time to station" is measured (foot, bus, or car)          |
| Style           | Description of the layout type of the apartment (1K, 1LDK,... ) |
|-----------------+---------------------------------------------------------------|
| Monthly rent    | Rent per month of the listing. In units of 10000 Yen          |
|-----------------+---------------------------------------------------------------|
The data collected is observational only and not representative of the Tokyo
real estate market as a whole.

In figure [[fig:hists]] we can see the distribution of values our variables take on.
We see that our target variable, "apt_rent", has a very long, thin tail to the
right. After taking the logarithm, the values move a lot closer, to 0 and take
on a more symmetric shape. As for the distribution of building age, we can see
that the number of buildings declines with age. In the number of floors of the
buildings, we see a spike at two floors, and then two sudden declines, at 5
and 15 floors respectively. The reason for these drops most likely lies in a
change of building regulation at certain heights. In the "Time to station" variable, we also
observe some irregularity around the 5, 8, and 10-minute marks, there being
sudden declines at each of the values. While most of these times were given in
minutes by foot, some also were given in minutes by Bus(1041 cases) / and minutes
by car(24 cases), which can be seen in the "Methods" plot, and is the reason the "methods"
variable was included.

#+NAME: fig:hists
#+LABEL: fig:hists
#+ATTR_LATEX: :name fig:hists :label fig:hists
#+CAPTION: This figure depicts the value frequencies of the variables used in our paper. Note that for the "Styles" variable, the x and y axes have been flipped for the readability of the labels.
[[./assets/varhists.png]]

"Styles" shows the distribution of the layouts classifications of the rooms. 1R
means "One room".[fn:1] The original dataset included layouts of apartments
until "11LDK", leading to a high cardinality. We included all layouts with more
than five bedrooms under the category "5+", which seems to be a comparatively
small group nonetheless. We can see that other than 1K and 1R, the "LDK" type
rooms seem to be the most popular layouts.

Figure [[fig:corrplot]] shows a correlation plot of all of the variables. Many of
the explanatory variables are quite highly correlated. This high correlation means
that an interpretation of coefficients in a linear regression model would be less
reliable. In this paper, however, we are not going to make any strong interpretations
based on our coefficients.
#+NAME: fig:corrplot
#+LABEL: fig:corrplot
#+ATTR_LATEX: :label fig:corrplot :name fig:corrplot :width 8cm
#+CAPTION: Heatmap showing the correlations of the variables displayed in [[tab:regression]].
[[./assets/corrplot.png]]

** Neural Network architecture
This subsection will explain the architecture of the Neural network we used and
some of the preprocessing and augmenation steps we performed.

For the construction of the Neural Network, we relied on the software libraries
~fastai~ [cite:@howard20_fastai], ~pytorch~ and ~torchvision~. (Pytorch and torchvision both by the pytorch team [cite:@NEURIPS2019_9015]). We built on the ~resnet50~ implementation by
[cite:@NEURIPS2019_9015] of the model outlined in
[cite:@he15:deep_resid_learn_image_recog]. We initialized the model's weights
to the pre-trained weights available in ~torchvision~. These weights are trained
using the "ImageNet" [cite:@imagenet2009] dataset.

We replaced the last layers with a custom adaptation to better fit the
regression task at hand. We used the same base model up until the first fully
connected layer, which we replaced with another untrained fully connected layer.
Initially, we used a fully connected layer with a single output as the final
layer. However, we found that sometimes the model would make unreasonably high
predictions, which complicated the model training by abnormally increasing the
loss, ultimately resulting in "exploding gradients". Thus, we decided to add
another layer to scale the Neural Networks output between a predetermined range.
In particular, we scaled the last layer's outputs with a sigmoid function. By
scaling the outputs of The neural network, we could prevent these problems at
the expense of introducing one hyperparameter, the y-range. To decide on the
y-range for our Neural network, we used the log-transformed target variable's
greatest lower and least upper integer bounds. Since the extreme values were
0.095, and 5.521, so we chose 0 and 6 as our bounds. This layer scales the
output vector from the Network elementwise according to the following rule.
\(s(x) = \sigma(x) (hl) + l \), where \( \sigma(x) = \frac{1}{1+e^{-x}} \), \( l \)
is the lower bound, and \( h \) is the upper bound. The outputs of this
function are then used to calculate the loss, ensuring that initial predictions
of the network are never unreasonably high, ultimately resulting in easier
training and convergence.

We used the mean squared error as a loss function, and before training the whole model,
we "froze" the base model, and trained our custom head only. After initial rounds
of training the head only, we "unfroze" the pretrained weights and trained the whole
neural network. The Resnet model and learning rate were optimized with
adam, and the initial learning rate schedule and the schedule was chosen as
suggested in [cite:@smith17_cyclic_learn_rates_train_neural_networ].

*** Preprocessing of images
We performed the three steps of preprocessing for all of the floorplan images.
1. Normalization
2. Rotation
3. Resizing
**** Normalization
We used the means and standard deviations of the pre-trained model to normalize
all input images. The original model was normalized with those weights, and thus
all of the weights are calibrated to expect normalized inputs. Should our inputs
not be normalized with the same values, the model's predictions might behave
unexpectedly.

**** Rotation
The rotational step is mainly implemented as a form of data augmentation. For
each image, there is a 25% chance to be rotated either 90, 180, 270, or 0(360)
degrees. This is done because while the floorplans usually do have characters
or writing, they do not have an intrinsic direction. The same floorplan,
with only its orientation changed, should functionally still be considered the
same floorplan. Furthermore, many floorplans have compass roses on them to
find out the orientation of the rooms. Note that mirroring the images would change
the compass' orientation. Thus we can easily see that mirrored floorplans are not
functionally the same, which is why we avoid mirroring our images.

**** Resizing
For efficient processing of the images, all images have to have the same size.
However, the images in the dataset collected have different sizes, so we had
to choose how to prepare the images. We decided to choose 224x224 pixels for our
images. This size is a conventional choice, which we did not find to have any
problems with. Most images in the dataset are between 200 and 400 pixels in
height and length, and we did not see a reason to adjust it. Images were cropped
lazily before feeding them into our model, so we were able to try different
approaches to resizing the image. Each approach has advantages and disadvantages
which we will outline below. We tried the following three approaches.

/Distorting/ the image to fit into 224 pixels by "squashing and squeezing" it
into the 224x224 pixels. With this approach, it is possible to retain
information from all image regions. However, when resizing like this, the amount
of distortion for each image varies based on the original size, and the
model has to process different degrees of distortions and the distorted proportions these
entail.

/Cropping out/ the center part of the image and padding with black if the
image's height or size is smaller than 224 pixels. One drawback of this method
is that if we were to exclude an essential part of the image, there would be no
information for the model to refer to. Furthermore, since the padded values are
all 0's, they result in wasted computation, thus inefficient training.

/Randomly cropping out/ a part of the image with the desired size. This method
has the same problem as the second approach, however by cropping out a random
part, rather than just the center, we can input the Neural Network a
wider variety of images, since even if we use the same image twice, there is a
high probability that the images are cropped differently. Furthermore, at evaluation
time we can crop the same image a few times, predict the different crops and
then average their predictions to obtain a prediction that considers more
area of each floorplan.

Figure [[fig:floorplan_transforms]] shows how different techniques influence the
different cropping methods and lets us observe some of the problems outlined.
The first row shows the distorted images. All images with the label 7.7 look
highly alike and are actually from the same building. However, while the first
and eighth picture images look the same, the ninth does not because the original
image contains more white on either side. Even though all images depict rooms
with almost exactly the same layout, after the distortion, one room looks quite
different. In the second row, we can see that the compass rose of the pictures
labeled 8.0 and 8.57 is cropped out. In their squished versions, however, it is
included. The last row depicts some images obtained by using the the random crop
method for the floorplan in the first column of the other rows. While we get
most of the details, with the correct proportions, due to the random nature of
our cropping, we do not have any image containing the apartment's balcony. The
third approach yielded the best results in some preliminary experiments. Thus
all results in this paper are reported using a model trained on predictions
by using the "Random Crop" strategy.

#+name: fig:floorplan_transforms
#+label: fig:floorplan_transforms
#+CAPTION: This figure showcases the properties of each resizing method. The first and second row compare 9 floorplans, the third shows different crops of the leftmost floorplan.
#+ATTR_LATEX: :name fig:floorplan_transforms :label fig:floorplan_transforms :width 15cm
[[file:./assets/resizes.jpg]]

** Hedonic Price estimation
The hedonic price estimation was performed via a multiple linear regression
model using all variables collected and outlined in [[tab:var_explanation]]. We
log-transform the target variable of apartment rent. While preliminary tests of
our Multiple regression model only showed a slight improvement in $R^{2}$, and
the coefficients, the Neural network's predictions improved significantly.
Furthermore, many of the research papers cited in this paper use log-transformed
rents as well, so we will side with convention. We created dummy matrices for
each of our categorical variables, ending up with 724 columns, including the
intercept and continuous columns. The "station" variable's cardinality of 684,
and the "style" variable's cardinality of 31 caused this significant increase in
dimension. Furthermore, we added a squared term for the "Time to station"
variable to the design matrix. We estimated three different models, one using
all variables, without the rent prediction of the Neural Network, one using all
variables with the rent prediction of the neural network, using only the neural
network and an intercept.
* Results
Moving onto the results of our analysis.
Firstly, we will look at the results quantitatively, and afterward, we will take a look at the
models and their predictions qualitatively by looking at some examples and
edge cases to better understand how the predictions work and how the model makes
its predictions.
** Quantitative
Table [[tab:regression]] shows the results for three models described in [[Hedonic
Price estimation]]. The first column shows the estimated coefficients and standard
errors, without the predictions obtained from the neural network (Hereafter
sometimes referred to as NN Factor), the second shows the estimated coefficients
with the predictions, and the last shows the values for the model with intercept
and the predictions of the neural network only. We included all categorical
variables in both of the first two regressions, but did not include their
coefficients in the table due to their high cardinality.
#+NAME: tab:regression
#+LABEL: tab:regression
#+ATTR_LATEX: :label tab:regression :name tab:regression
#+INCLUDE: "assets/table2.tex" export latex
Looking at this table, we observe a considerable increase in the explanatory power of the model using the NN's predictions over the one that does not include the NN's predictions. The \( R^{2} \) value moves from
0.915, to 0.945, and the Residual Std. Error is reduced from 0.127 to 0.101,
a reduction in error of \( \approx 20\% \). The signs of the coefficients in the models are as
one would expect them to be and do not change with the inclusion of the Neural network prediction.
However, the magnitude of the coefficients moved toward 0 in every case.
Furthermore, the previously non-significant factor of "Admin fee" became
significant after the inclusion of the new feature. A similar pattern holds for the variables
included in the regression but not in this table. Most
of these coefficients moved toward 0, neither changing sign nor significance.

** Qualitative

Next, we would like to look at our models' predictions more qualitatively. In figure [[fig:residual_plots]] we plotted the predictions against
their actual values to try and see whether there are any patterns of
mispredictions in our models. We can see that all of our models seem to
overpredict the most expensive properties. In [[fig:residual_plots]] we drew a
dotted line at \(x=log(100) \approx 4.6\). After this point, all models seem
to overpredict the rent prices greatly. While the linear models have few
but very high over-predictions, the Neural Network's residuals are smaller
but have shifted systematically. The reason for the relatively low
residuals of the Neural network is that we used scaled its predictions with
the sigmoid layer discussed in [[Models, Methods, Architecture]]. Furthermore,
the neural network underpredicts many low rent properties, possibly
because, in some of these cases, the properties have a good location, to which
they owe their higher prices.
#+LABEL: fig:residual_plots
#+NAME: fig:residual_plots
#+ATTR_LATEX: :height 4cm :label fig:residual_plots :name fig:residual_plots
#+CAPTION: This image shows the residuals of the predictions of the two models and the Neural network. The x and y axes for all of the plots are the same. The dotted blue line is drawn at \( x = log(100) \approx 4.6 \).
[[./assets/residual_plot.png]]

Next, we would like to examine some predictions of the models in even more
detail.
We will look at the following patterns of predictions.

1. Some random predictions
2. The highest and lowest predictions of the network
3. The predictions that were the most due to input of the Neural Network
4. Predictions for properties with similar characteristics but whose value considerably changed due to the Neural network predictions.

Firstly, we will look at some randomly extracted images in figure
[[fig:random_examples]]. We show these predictions mostly to showcase the available
floorplans and the targets. The Neural network is not radically off with any
prediction in this example, with the highest difference in prediction and price
being 17000¥. However, it is hard to tell exactly why the Neural Network made
the predictions it did. Some of the more extreme predictions are more easily
discernible patterns. Some of these more extreme predictions are due to problems
with the dataset. However, they also seem to give us some insight into how the
Neural Network is making its predictions, so instead of removing these cases and
retraining the model right away, we decided to still explore them in this
section.

#+LABEL: fig:random_examples
#+NAME: fig:random_examples
#+ATTR_LATEX: :height 4cm :label fig:random_examples :name fig:random_examples
#+CAPTION: This image shows the NN's predictions and ground truths for a randomly extracted sample of the dataset. (In 10,000¥)
[[./assets/random_table.png]]

Moving onto more extreme cases, we tried looking at the highest and lowest
predictions in Figures [[fig:negtop]] and [[fig:postop]]. Here we show images that the Neural
Network's predictions were the lowest and highest for.
#+LABEL: fig:negtop
#+NAME: fig:negtop
#+ATTR_LATEX: :label fig:negtop :name fig:negtop :height 4cm
#+CAPTION: These are the four predictions the model predicted the lowest rent for. (in 10,000¥)
[[./assets/rand_neg_top_100.png]]
The floorplans for figure [[fig:negtop]] are solely
for dormitory or boarding house-like apartments. The model seems to have picked
up on the repetitive pattern in the floorplan often present in these apartments.
Although the overall size is of the floors is quite extensive, and the floorplan
spans multiple floors. The model's predictions seem to be at least aware that
only a single room is considered. However, as we see later in the leftmost
picture of figure [[fig:upward]], the model cannot correctly tell these kinds of
shared-living spaces from big apartments intended for a single household. Note
that the predictions for the middle two floorplans were different even though
the floorplans are the same. This is due to the preprocessing step where we
randomly crop our images. When making the two predictions for the middle
floorplans, the model thus had slightly different inputs and outputs. This image
appears twice in the dataset because two different rooms in this building were
open for rent, which explains the difference in actual prices.

#+LABEL: fig:postop
#+NAME: fig:postop
#+ATTR_LATEX: :label fig:postop :name fig:postop :height 4cm
#+CAPTION: The floorplans of the four apartments with the highest predicted rents. (in 10,000¥)
[[./assets/rand_top_100.png]]
Moving onto the highest predictions of the Neural network, in figure [[fig:postop]] we see that the Networks residuals are much higher.
The model seems to choose spacious apartments with multiple floors, prominent balconies
and a non-repetitive layout for its highest predictionsin .
Overall, however, it is harder to find a definitive pattern in the highest predictions of the model.

#+LABEL: fig:downward
#+NAME: fig:downward
#+ATTR_LATEX: :height 4cm :label fig:downward :name fig:downward
#+CAPTION: This image shows the floorplans of the apartments with the biggest decreases in prediction after considering Neural Network output. (in 10,000¥)
[[./assets/overpreds.png]]
Figure [[fig:downward]] and [[fig:upward]] have a slight change
in format. In these Figures, we compare the differences in the predictions of
Models 1 and 2 for a given apartment, to find the observations where the
Neural Network prediction had the largest impacts. These predictions were
performed using all available variables. Furthermore, we display the floorplans
and the Neural Network's predictions. Figure [[fig:downward]] shows the greatest
downward shifts due to the Neural Network predictions. Here, we again have the
problem of the same picture being present multiple times. The property with the
middle floorplan was posted to the website under different names by different
agencies multiple times, even with different prices. It is quite large
with a nice location, which is why the Linear Models
overestimate it so largely. Another reason for this big performance difference is
that while we are scaling the Neural Networks predictions, we are not doing
anything the like for the Linear Model. In the rightmost picture, we can see
that the model's prediction was far below the property's actual value,
while the linear model's predictions were much closer to the actual value. This
seems to be due to the simplistic layout of the property. Upon further
investigation, it also turned out that his property is an office space
that was mistakenly posted on the wrong part of the website.

Finally, we will look at the greatest upward movements after considering the
predictions of the neural network.
#+LABEL: fig:upward
#+NAME: fig:upward
#+ATTR_LATEX: :height 4cm :label fig:upward :name fig:upward
#+CAPTION: The floorplans of the apartments with the biggest increases in predicted rent due to the Neural Network input.
[[./assets/underpreds.png]]
The first floorplan was posted for a room available in a
shared flat, and for this property, the first model's predictions are much more
accurate than the other two predictions. This is because the Neural Network
overpredicted the rent by a lot. The reason for this seems to be that the
The neural network was considering the floorplan as a whole, while the actual
apartment that was up for rent is only a single room in the floorplan. A
similar problem most likely occurred with the third floorplan, which displays the
apartment's floorplan and a balcony that everyone living in the
apartment seems to be able to use.

* Discussion
Some of our results are hard to interpret, e.g., multimodal learning is worse
than the ensembling method. (probably) Why?
** Problems of very high dimensionality due to many categories in the categorical variables.
** The Neural Network seems to be very positive with its predictions; is there something we can do about it?
** Introduction
In this paper we found that utilizing the floorplans of rental apartment can
improve the predictive power of Linear Regression models when not many variables are available.
We suppose that the reason for this increased effectiveness is twofold:
1. By using the floorplans, the Neural Network had access to the factors that
   most influence residential satisfaction of experience with a certain
   property.
2. The increase in explanatory power seems extraordinarily high because we had
   much less explanation than other studies on hedonic pricing.
Most studies we reviewed made use of many more explanatory variables, especially about
structural features of the apartments, and we believe by using those, the improvement
of predictive power that our NN provided would be expected to decrease.
However, we believe that under many circumstances it might be easier to obtain floorplans
of apartments rather than the tabular data of the categorical features, so our
method could be used by parties like that.
While this study was exploratory only, further investigation might include how this method
fares with floorplans in different markets. While this time, only the market in and around
Tokyo was considered, and rent prices were mostly stable because we only had a single
location to deal with, we can easily imagine that larger discrepancies in price due to
location only could cause trouble with our model. One potential remedy for this problem could
be training the model on residuals of a Multiple Linear Regression controlling for location.

Another problem with the current model is that it is hard to interpret why the model is
making some of the decisions. For example [cite:@NIPS2017_7062] provide an approach for
model interpretation sometimes also applied to computer vision. Analyzing the current model
using the technique outlined here might give us more into the model's internals, which might
in turn lead to insights about consumer behavior as well.

Currently the Neural Network seems over predict prices on high-end properties, which might
be another avenue that we could improve the model for.

** Evaluation
*** Analyze
*** Offer explanations
*** Reference the literature
*** State imlpications

* Conclusion
Overall, we used real estate data collected from a publicly available website,
to train a Residual based Convolutional Neural Network for prediction of rent
prices based solely on that properties' floorplan. We also showcased some tweaks
to enhance the original model, to allow for quicker training and
convergence. We showed that it is possible to effectively leverage floorplan
image information to prediction rent prices, and that these predictions can
enhance other more traditional models' predictive power. While we did not have any
access to very detailed information about the apartments themselves, and thus
were not able to test the effectiveness of floorplan image analysis against,
models making use of more tabular data, we believe that using floorplan data
could be an option for entities trying to estimate rent prices,
without the need for interviewing participants. Our results seem to be inline
with existing literature on the topic of real-estate value composition, however
we believe that this paper shows initial evidence that is using Computer vision for
some instances of rent prediction might be more practical than traditional, manual ways o feature collection.

\printbibliography
* Footnotes
[fn:2] They use the word 基礎環境, referring to items such as ventilation, lighting or insulation.
[fn:1] The way to interpret these layouts is as follows: The Number at the
beginning denotes the number of bedrooms. Following that, come the letters "S",
"L", "D" and "K", which stand for "Service", "Living", "Dining" and "Kitchen."
respectively. Thus a "2LDK" apartment would have two bedrooms, one living room, one
dining room, and one kitchen. Service often stands for a small room without enough
lighting or ventilation to count as a bedroom. These rooms are often utilized
for storage. In figure [[fig:hists]], 1R stands for ワンルーム(1 Room), a layout in
which there either is no Kitchen, or there is no partition between the kitchen
and the bedroom.
