#+title: WIP Using Deep Learning to Assist Modelling of Tokyo Real Estate Prices
#+SUBTITLE: WIP An evaluation of an incorporation of deep learning methods for prediction real estate prices
#+AUTHOR: Jiyan Jonas Schneider
#+EMAIL:     jiyan.schneider@gmail.com
#+DATE:      2021-12-20
#+LATEX_HEADER: \usepackage[backend=biber, style=apa,]{biblatex}
#+LATEX_HEADER: \usepackage{xeCJK}
#+BIBLIOGRAPHY: /Users/jiyanschneider/Dropbox/Documents/lib/bibliography/bibliography.bib
# #+LATEX_HEADER: \setCJKmainfont{HiraginoSans-W0}
#+LATEX_HEADER: \setmainfont{EBGaramond-Regular}
#+latex_class_options: [12pt]
#+LATEX_HEADER: \usepackage[a4paper,left=2.5cm,right=2.5cm,top=2.5cm,bottom=2.5cm]{geometry}
#+OPTIONS: toc:nil

#+begin_abstract

The aim of this study is to examine the viability of using Deep Learning methods
and what they might have in housing. Although there have been quite a few
studies investigating the use of Machine Learning methods for this kind of task.
The novelty in our study primarily lies in the use of Deep Learning methods for
computer vision to analyze the images of the floor plans to assist with
prediction and our analysis of the way the neural network is able to use the
floor plans for prediction. There have been have been quite a few papers about
the use of Machine Learning methods for real estate price predictions, however,
most of the do not make use of deep learning, and even if they do, they do not
make use of the actual floor plan, but mostly rely on structured explanatory
variables for the their models. Some recent examples include,
[cite:@park2015using] and [cite:@sangha21_proper_norweg] , for the German
housing market and autocite:sangha21_proper_norweg for the Norwegian housing
market. In order to compare our results to other results, we also reconstruct
some models often used in the literature as baseline models.

#+end_abstract

* Introduction [This is still pretty poorly written]


** Find some nice introduction of why real estate markets matter

The real estate market has some defining features that make it different to
other kinds of markets. For example while competition in growing cities is
always pretty high, the goods sold could hardly be described homogenous /I have
no idea what im saying/.

* Background

** Current real estate models
Most real estate models are based on easily observable features of each kind of
rental apartment, such as the zip-code, the closest station, or the number of
rooms in each apartment. It

** We want to consider the room layout
However the actual layout of each apartment could also be considered to a very
important aspect of each apartment, however, since it is hard to describe the
apartment layout precisely in words, in other words, hard to categorize, most
analyses of house prices thus ignore the problem of precisely incorporating
information about the apartment layout.
** 2 main questions
In this paper we will try to answer 2
main questions.

 1. Does having information about the room layout, help with the prediction for
    any model? To test this we will try to predict the price of the apartment
    solely with the CNN
 2. If there is an effect of considering the room layout, how do we build the
    model that is most efficient for prediction.
    1. For example we could use the output of our model together with a linear
       model for the categories, like in 1.
    2. We could make it kinda ensemble like, using the output of multiple
       models, and using another linear model to combine them ( Or other
       ensemble methods )
    3. We could use a multimodal approach, where we output latent states with
       each of our submodels and use a "head" model to fuse our latent states
       as described in:

* Data

The dataset used is a mix of tabular and image data of rental real estate
properties from the Tokyo Metropolitan area, listed on a public website. The
data was collected for the purpose of writing this paper. The Tokyo metropolitan
area includes parts of Yokohama, Saitama and Chiba.

used various methods in attempts to subdivide the real estate markets to be able
to more accurately model the different structures of this market, and by
limiting ourselves to only the Tokyo Metropolitan area, we try to sidestep the
problem of having to accomodate for the different kinds of markets as has to be
done in


** This selection of data has been justified by the fact that

For each listing we used the dependent variable, the monthly rent
of the apartment, the image of the floorplan of the apartment, 5 continuous and
3 categorical variables.

#+CAPTION: An explanation of the variables that were collected and used in this study.
#+Name: var_explanation
|-----------------+-----------------------------------------------------------------------------------------------------|
| Variable        | Explanation                                                                                         |
|-----------------+-----------------------------------------------------------------------------------------------------|
| station         | Name of the closest public transport station, (by travelling period)                                |
| method          | Description of the layout type of the apartment of the type of apartment (for example 1K, 1LDK...)  |
| apt_style       | Number of floors of the building of this listing                                                    |
|-----------------+-----------------------------------------------------------------------------------------------------|
| apt_floor       | The floor the property is on property                                                               |
| apt_size        | Size of property in $m^2$                                                                           |
| time_to_station | No. minutes of taking "method" to the next station                                                  |
| b_age           | No. of years ago the property was built                                                             |
| b_no_floors     | No of floors of the building                                                                        |
| apt_admin_price | Amount of monthly administration fee                                                                |
|-----------------+-----------------------------------------------------------------------------------------------------|
| apt_rent        | Rent per month of the listing. In units of 10000 Yen                                                |
|-----------------+-----------------------------------------------------------------------------------------------------|


The data was collected representative of the Tokyo realestate market, and
our anlaysis can not be considered as an analysis of the Tokyo realestate market
as a whole, but rather it serves as a way for us to outline how to use our
methods. However, the results from this paper should not be used for
interpretations on the Tokyo real estate market as a whole. Two more potential
sources of bias in the dataset are that we are only considering properties that
were listed at the time of data collection, and that we rely on data from a
single website, and are not making use of other sources. However, these biases
are not expected to have an impact on our results, in this paper we are more
concerned with the efficacy of the different measures, rather than making
statements about the Tokyo Real-estate market.
:w

** Variables Used
We did some dataprocessing for the variables. We prepared each variable as below.
** Summary stats

** Some more data explanation with some plots
* Models, Methods, Architecture
We will assess the problem of whether or not image data is worth it by. constructing the
predictions for the apartment rent, and using these predictions, together with the rest of
the variables to assist prediction of the actual apartment rent.
For the assessment of whether or not
*** Cite Resnet
*** Cite pretraining paper
*** Cite Embedding paper
*** Cite Learning Rate paper
** Baseline models with columns only to compare our model to
Give reasons for why we chose those models ( e.g. other papers used those models )
*** Multiple Linear Regression
 - [ ] Explain base class of the One hot encoded things and a little bit of multiple linear regression.
   Make the model. If it becomes too long, explain it simply with the vector representation, this probably
   does not have to be too exact.
   \( \hat y = \beta_{0} x_{0} + \beta_{1} x_{1} + \beta_{2} x_{2} \)

** Practical Adjustments that had to be made
*** Explain how we crop our pictures

In order to efficiently process images on the GPU, all images have to have the
same dimensions. However the images in the dataset colected had different
dimensions, so the images have to be cropped. We cropped all images to 224x224
pixels. The choice for this size seemed to be a good fit since most images in
our dataset are between 200-400 pixels in both, height and length. Other than
for this reason, however, the size was picked mostly out of convention. The
images were cropped lazily before feeding them into our model, so we were able
to try different approaches to cropping the image. We found that the third
approach described below worked best for our dataset.

1. Cropping out just the middle part of the image and padding with black if the
   images height or size was smaller than the 224 pixels. One drawback with this
   method is that if we were to crop out an important part of the image, there
   would be no information for the model to refer to. Furthermore, the padded parts
   are wasted computations.
2. Distorting the image so that fits into the 224 pixels by "squashing" it into
   the 224x224 pixels. With this approach it is possible to retain all parts of the
   image, so that no important parts are left out, however, when resizing like this,
   the amount of "squishing" done for each image varies, so the model has to learn
   to deal with different amounts of distortion. This method entails with it
   another drawback discussed in [[ ] ]]]]]]]]]]]]
3. Cropping out not the middle part of the image, but a random part of the
   image. This problem entails with it the same problem as approach 1, however
   by cropping a random part, rather than just the center, we have more possibility of training the neural network, since even if we use the same image twice, there is a
   high probability that the images are cropped differently. This is a technique that
   is often used as a means of data augmentation as well.
We had the best results for training the "Vision" part of our Neural network,
when using the third approach, and results reported in this paper were done with
"Random Crop" strategy.
**** You might need to update this picture.
:PROPERTIES:
:ID:       c104b241-3f4e-4b3a-84f9-171d5119dd4b
:END:
#+HEIGHT: 500
#+CAPTION: This figure showcases the properties of each kind of resize as outlined in the paper. The first row shows some 9 floor plans where the data has been Resized with the "squish" method. The second row shows the same picture with the crop-and-pad method, and the third row shows the first apartment of the other two rows, randomly cropped to different sizes. The black parts of the second and third rows are the padded parts.
[[file:./assets/resizes.jpg]]

*** Explain what other tricks we used
*** Explain the embeddings I will use for the Neural Network
For the Neural Network part of the architecture we made use of Categorical Embedding layers
We used the

*** Exactly explain how the model is trained
 - Learning rate adjustment
 - Pretrained resnet 50
 - For the categorical ensemble thing, that first the network is trained,
   then weights are frozen, and that only the new head of the resnet50 is trained at first, for a few epochs,
   and at the end we train both models
 - Same for the output
* Results
** Results for our model
** Results for vision model put into Linear Regression ( Is the prediction column statistically significant? )
** Results of baseline models
* Discussion
Some of our results are hard to interpret, e.g. multimodal learning is worse than the ensembling method. (probably) Why?
** Problems of very high dimensionality due to many many categories in the categorical variables.
* Conclusion
** Conclude whether using these models might make sense or not
Some of our
** Further possible investigations
Some possible talking points:
 - If the results are good, would looking at a bigger market be interesting
 - If we had a more representative sample, could we use some of the results to make some
   interesting conclusions
 - It would be interesting to analyze the outputs using methods as described in for example with shap or eli5, to see
   why it doesn't work if it doesn't or what it focuses on for certain predictions, if it does.
 - How does everything look for the multimodal approach, does it make sense or not?
And ways to improve the model

** Cite Fastai

\printbibliography
