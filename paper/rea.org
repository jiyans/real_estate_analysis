#+title: WIP Using Deep Learning to Assist Modelling of Tokyo Real Estate Prices
#+SUBTITLE: WIP An evaluation of an incorporation of deep learning methods for prediction real estate prices
#+AUTHOR: Jiyan Jonas Schneider
#+DATE: 2021-12-20
#+LATEX_HEADER: \usepackage{xeCJK}
#+BIBLIOGRAPHY: /Users/jiyanschneider/Dropbox/Documents/lib/bibliography/bibliography.bib
#+LATEX_HEADER: \setCJKmainfont{HiraginoSans-W3}
#+LATEX_HEADER: \usepackage[backend=biber, style=apa]{biblatex}
#+LATEX_HEADER: \setmainfont{EBGaramond-Regular}
#+LATEX_HEADER: \usepackage[a4paper,left=2.5cm,right=2.5cm,top=2.5cm,bottom=2.5cm]{geometry}
#+LATEX_HEADER: \usepackage{graphics}
#+LATEX_HEADER: \usepackage[doublespacing]{setspace}
#+LATEX_CLASS_OPTIONS: [12pt,titlepage]
#+OPTIONS: toc:2 H:4


#+begin_abstract

This study aims to examine the structure of real estate rental prices,
taking into account the property's layout. We find that when using computer
vision methods to analyze the apartment rent The aim of this study is to examine
the viability of using Deep Learning methods and what they might have in
housing. There have been quite a few studies investigating the use of Machine
Learning methods for this kind of task. The novelty in our study primarily lies
in the use of Computer Vision Deep Learning methods to analyze the images of the
floor plans to assist with prediction. By making use of one of the computer
vision models described in [cite:@park2015using] to create an attractiveness
measure based solely on the floorplan, we can improve a regular hedonic
pricing model from an $R^{2}$ of 0.915 to an $R^{2}$ of 0.945. This suggests
that floorplans contain considerable information about rent prices
and thus consumer behavior, which is not usually covered in hedonic
regressions.

#+end_abstract

* Introduction
The problem of real estate value estimation comes up in multiple forms
throughout economics and society, with many kinds of actors being interested in
predicting housing and real estate prices. Appraisers and tax assessors conduct real-estate appraisals, fundamental value analyses are
conducted by investors [cite:@krainer2004], and it is reasonable to assume that
other parties such as banks have methods of assessing the price of a property
as well, for their mortgage lending operations. This kind of real estate
appraisal might be done individually, with nationally certified
appraisers estimating the value of a house. However, it is also conducted in
different contexts. For example, on a larger scale, the potential rent that a
property would receive on the market at a given time has to be estimated or
imputed for use in determining certain economic variables such as the GDP. In economics, real estate prices are often considered
hedonic prices, meaning that the final price of a good is determined by the
parts that make it up, and hedonic methods are often the de facto methods for real estate price estimation. [cite:@weko_55303_1]

For these reasons, much research on real estate pricing has been conducted, and
most of this research uses purely tabular data. However, non-tabular
data, like the actual floorplans of the real-estates, contains valuable
information not easily expressed in a more tractable format. The underlying
hypothesis of this research paper is that the floorplans expose some properties
that are valuable to consumers and can be leveraged with Deep Learning. By
doing this, we hope to advance our insight into the price structure of real
estate, consumer behavior in the longer run.

To achieve this, we first collected tabular data and the floor plans of over
100,000 rental apartments in the Tokyo Metropolitan area from a publicly
available website. Then we used the Neural Network architecture described in
[[Models, Methods, Architecture]] to predict the rent of each apartment given only
its floorplan, and lastly, we used these predictions together with a traditional
hedonic regression model to ascertain the effect that the Neural Network has.

Doing this, we find that the Neural network is able to explain a large
proportion of the rent price of many properties and considerably improve the
explanatory power of the hedonic regression model. We suppose that the reason
for this increased effectiveness is twofold:
1. By using the floorplans, the Neural Network had access to the factors that
   most influence residential satisfaction of experience with a certain
   property. [cite:@choi2003]
2. The increase in explanatory power seems extraordinarily high because we had
   much less explanation than other studies on hedonic pricing.
We will expand more on these points in the [[Background]] and [[Discussion]] sections.

There were other attempts to incorporate Machine Learning methods for
unstructured, visual data about real estate properties. For example,
[cite:@hattori2019rent] uses Principal Component Analysis to extract a feature
vector from floorplan data and subsequently uses this vector in various models. However, they report that while there are slight improvements
in prediction, it is challenging to find merits for using their approach
because these improvements are too small. [cite:@zeng2019deep] use a computer
vision on floor plan images. However, they are looking to find out
functionalities of different elements within a floor plan and are not using it
for rent prediction. Lastly, [cite:@poursaeed2018] uses pictures of exteriors and
interiors of properties to improve price predictions. Their approach improves
predictions as well. However, they are not making use of the actual floorplans
of the properties. While their approach certainly seems to be valuable,
floorplans reflect properties that are intrinsic to their real estate
property, while pictures of interiors carry with them much subjectivity. When
analyzing photographs, the quality, lighting, angles, and interior furniture
would be expected to affect the evaluation of a property. Floorplans, however, mainly when prepared professionally, include properties intrinsic
to a specific estate, for example, the sizes of the different rooms and their
relative location to each other.

* Background
Real estate rental prices are a much-studied topic and are tackled from
many different kinds of perspectives. Many studies about real-estate appraisal,
imputation, or prediction use cross-sectional tabular data.
[cite:@akiyama_yuki2019320204;@weko_55303_1;@limsombunchai2004]

There are, however, also other avenues of study about different kinds of real
estate prices, for example, financial/time-series based attempts to understand
real estate prices. [cite:@krainer2004]

Because of all these different ways of considering real-estate prices,
considerable literature on the structure of real-estate prices has accumulated. While these different kinds of ways of looking at real-estate prices are usually performed by different parties pursuing different kinds of goals, they all study real-estate prices in some way, which is why we lean on them in this paper ??????? In this section, we will discuss some
of the past literature from these different fields, to get an overview of how
significant floorplans could even be in the topic of real estate price
structure.

Most studies agree that real-estate prices consist mostly of factors belonging
to one of two categories. Either structural factors about the properties in
question, for example, its size, the number of rooms, or the type of the rooms.
Alternatively, the environmental factors are not directly included in the
apartment but are related to the environment of the properties' location. For
example, the distance to the closest schools, the city center, or the nearest
train station. These factors might change depending on the market, as different markets tend to have their peculiarities. For example, in big Japanese cities,
people tend to a higher proportion of their income on rent and tend to put
a higher relative value on property location than in other places.
[cite:@salarymen1999]


[cite:@choi2003], a study about the causes of residential satisfaction
conducted through a survey, finds that these two categories can be further
subdivided. Their study lists 35 items for the survey participants to
fill their satisfaction levels with. Later in their paper, they classify these
items into six groups. Three big groups, containing most of the items, and three small
groups, each with a single item, not belonging to any of the big groups in
particular. The three big groups are the "Living environment（住環境）", the
"Fundamental environment（基礎環境）[fn:2]", and the "Size and Facilities"（広さ・
設備） groups. Furthermore, in their study, they find that the factors
contributing most to overall residential satisfaction come
from the "Fundamentals environment" and "Size and Facilities" groups. In table
[[tab:satisfaction_items]], we show the items that the survey participants were
asked about.
#+LABEL: tab:satisfaction_items
#+NAME: tab:satisfaction_items
#+ATTR_LATEX: :name tab:satisfaction_items :label tab:satisfaction_items
#+CAPTION: Table describing the groups and items participants were asked to judge their satisfaction by,  in [cite:@choi2003].
| Fundamental Environment | Size, and Facilities        |
|-------------------------+----------------------------|
| Lighting                | Overall Size               |
| Ventilation             | Floorplan                  |
| Condensation (or dew)   | number of rooms            |
| Insulation              | Interior design and Finish |
| Noise                   | Storage space              |
| Outward appearance      | Kitchen space              |
|                         | Kitchen facilities         |
|                         | Washing room space         |
|                         | Washing room facilities    |
|                         | Bathtub size               |
We believe that information about many of these factors, which [cite:@choi2003]
found to be most important in determining residential satisfaction, or some
derivations thereof can be found in floorplans. The original study only has data
about the satisfaction with these factors and how they are related to overall
satisfaction. However, the satisfaction with storage space is not equal to the
storage space, surely they are highly and positively correlated. While it is
not easily possible for us to infer the satisfaction an individual might feel
for the storage of a given apartment from its floorplan only, it is possible to
infer the size of the storage space. Since we are assuming these to be at least
slightly positively correlated, some information is thus available about this
factor from the floorplan. Since these factors are predictive of satisfaction,
it also seems reasonable to expect that they are to some extent predictive of
apartment rent.

This paper aims to use computer vision techniques to analyze the
floorplans, assuming that they offer some information about rent not
traditionally included in many hedonic price estimations. Specifically, we
believe that floorplans offer information about most items in the "Size and
Facilities" column of [[tab:satisfaction_items]]. Furthermore, many floorplans include
information about the windows, the cardinal direction of the apartment, and some
even include the placement of air conditioning machines. Thus floorplans hold
information about the Lighting and Ventilation items of the "Fundamental
Environment" columns as well. Furthermore, floorplans also contain information
about more complicated notions that were not asked in the study, possibly
because they are complicated. Examples of this could be the proportions
of rooms relative to each other or whether the shower and toilet are located in
the same room or not.

Moving away from the satisfaction study a bit, many of these factors are even
less readily formulated as objective measurements one would try to use when
conducting an econometric hedonic price estimation of rental prices. There seem
to be too many categories to consider. For example, while overall size seems to
be an essential measure considered and available in most datasets, kitchen size
or bathtub size is much less readily available. Thus the above factors
become even harder to consider when using objective measurements. By utilizing
an apartments floorplan, however, it seems as though it should be possible to
obtain information about at least some of

* Data
The dataset used is a mix of tabular and image data of rental real estate
properties from the Tokyo Metropolitan area, listed on a public website. The
data was collected to write this paper.

We focused on rental apartments in Tokyo in particular because, as outlined in
[cite:@weko_55303_1] and [cite:@akiyama_yuki2019320204], real estate
prices are estimated throughout different markets becomes more challenging. As a showcase for
the increased difficulty, consider [cite:@akiyama_yuki2019320204]. First, they
rely on the K-Means++ algorithm and the Gap statistic to create clusters for
different real estate markets and then, in their subsequent analysis, use
these clusters to analyze their data on a by-market basis. As this is an
exploratory study, we decided that by focusing on "roughly" a single market, we
can sidestep this problem and focus on the viability of these computer vision
methods first.


For each listing, we have the monthly rent of the apartment, the image of the
floorplan of the apartment, 5 continuous and 3 categorical variables. The
details for the tabular variables are described in Table [[tab:var_explanation]].
#+LABEL: tab:var_explanation
#+NAME: tab:var_explanation
#+CAPTION: Explanation of the variables collected and used in this study.
#+ATTR_LATEX: :name tab:var_explanation :label tab:var_explanation
|-----------------+---------------------------------------------------------------|
| Variable        | Explanation                                                   |
|-----------------+---------------------------------------------------------------|
|-----------------+---------------------------------------------------------------|
| Floor           | The floor the property is on property                         |
| Size            | Size of property in $m^2$                                     |
| Time to station | No. minutes of taking "method" to the next station            |
| Age bldg.       | No. of years ago the property was built                       |
| Floors bldg     | No of floors of the building                                  |
| Admin fee       | Amount of monthly administration fee                          |
|-----------------+---------------------------------------------------------------|
| Station         | Name of the closest public transport station                  |
| Method          | How "Time to station" is measured (foot, bus, or car)          |
| Style           | Description of the layout type of the apartment (1K, 1LDK,... ) |
|-----------------+---------------------------------------------------------------|
| Monthly rent    | Rent per month of the listing. In units of 10000 Yen          |
|-----------------+---------------------------------------------------------------|
The data collected is observational only and not representative of the Tokyo
real estate market as a whole.

** Summary stats
In figure [[fig:hists]] we can see the distribution of values our variables take
on. We see that our target variable, "apt_rent", has a very long, thin tail to
the right. After taking the logarithm, the values have moved a lot closer, to 0
Moreover, the distribution looks a lot more symmetric. As for the age distribution, we
can see the number of buildings declining with age. In the number of floors of
the buildings, we see an up spike at two floors, and then two sudden declines, at 5
and 15 floors, respectively. The reason for these spikes most likely lies in a
change of building regulation. /// citation needed ?? and what change exactly?

In the "Time to station" variable, we also observe some irregularity around the
5, 8, and 10-minute marks, there being sudden declines at each of the values.
While most of these times were given in minutes by foot, some also were given in
minute by Bus(1041 cases) / and minutes by car(24 cases), which can be seen in
the "Methods" plot.

"Styles" shows the distribution of layouts of the rooms. 1R means "One
room".[fn:1] The original dataset included layouts of apartments until "11LDK",
leading to a high cardinality of the variable. For this reason, we included all
layouts with more than five bedrooms under "5+". We can see that other than 1K and
1R, the "LDK" type rooms seem to be the most popular layouts.

#+NAME: fig:hists
#+LABEL: fig:hists
#+ATTR_LATEX: :name fig:hists :label fig:hists
#+CAPTION: This figure depicts the value frequencies of the variables used in our paper. Note that for the "Styles" variable, the x and y axes have been flipped for the readability of the labels.
[[./assets/varhists.png]]

* Models, Methods, Architecture
This section will explain the two parts essential parts of the method used
in this paper. First, we will explain how we built the neural network
responsible for rent estimation based solely on the floor plan, and after that,
we will discuss the hedonic pricing method used for confirmation.
** ResNet
For the construction of the Neural Network, we relied on the software libraries
~fastai~ [cite:@howard20_fastai] and ~pytorch~ [cite:@NEURIPS2019_9015]. We
build on the ~resnet50~ implementation by [cite:@NEURIPS2019_9015] of the model
outlined in [cite:@he15:deep_resid_learn_image_recog]. We initialized the
model's weights to weights pre-trained on the "ImageNet."
[cite:@imagenet2009] dataset.

However, we replaced the last layers with a custom adaptation to better fit
the regression task at hand. We used the same base model up until the first fully connected layer, which we replaced with another untrained fully connected layer. Initially, the final layer was a fully connected layer with a single output. However, we found that sometimes the model would make unreasonably high predictions, which complicated the model training by abnormally increasing the loss, ultimately resulting in "exploding gradients".
Thus, we decided to add another layer to scale the Neural Networks output between a predetermined range.
In particular, we scaled the last layer's outputs with a sigmoid function.
By scaling the outputs of The neural network, we could prevent these problems at the expense of
introducing one hyperparameter, the y-range. To decide on the y-range for our
Neural network, we used the log-transformed target variable's greatest lower and least upper integer bounds. Since the extreme values were 0.095, and
5.521, so we chose 0 and 6 as our bounds.

This layer scales the output vector from the Network elementwise according to
the following rule.
\( s(x) = \sigma(x) (hl) + l \), where \( \sigma(x) = \frac{1}{1+e^{-x}} \),
\( l \) is the lower bound, and \( h \) is the upper bound.
The outputs of this function are then used to calculate the loss,
ensuring that initial predictions of the network are never unreasonably high,
ultimately resulting in easier training and convergence. The Resnet model and
learning rate were optimized with adam, and the initial learning rate schedule
and the schedule was chosen as suggested in
[cite:@smith17_cyclic_learn_rates_train_neural_networ].

*** Preprocessing of images
We performed the three steps of preprocessing for all of the floorplan images.
1. Normalization
2. Rotation
3. Resizing
**** Normalization
We used the means and standard deviations of the pre-trained model to normalize
all input images. The original model was normalized with those weights, and thus
all of the weights are calibrated to expect normalized inputs. Should our inputs
not be normalized with the same values, the model's predictions might behave
unexpectedly.

**** Rotation
The rotational step is mainly implemented as a form of data augmentation. For
each image, there is a 25% chance to be rotated either 90, 180, 270, or 0(360)
degrees. This is done because while the floor plans usually do have characters
or writing, they do not have an intrinsic direction. The same floorplan,
with only its orientation changed, should functionally still be considered the
same floor plan. Furthermore, many floor plans have compass roses on them to
find out the orientation of the rooms. Note that mirroring the images would change
the compass' orientation. Thus we can easily see that mirrored floorplans are not
functionally the same, which is why we avoid mirroring our images.

**** Resizing
In order to efficiently process images, all images have to have the same size.
However, the images in the dataset collected had different dimensions, so we had
to choose how to prepare the images. We decided to choose 224x224 pixels for our
images. This size is a conventional choice, which we did not find to have any
problems with, most images in our datasets were between 200 and 400 pixels in
height and length, and we did not see a reason to adjust it. Images were cropped
lazily before feeding them into our model, so we were able to try different
approaches to resizing the image. Each approach is a trade-off, which we will
outline below.

/Distorting/ the image to fit into the 224 pixels by "squashing and
squeezing" it into the 224x224 pixels. With this approach, it is possible to
retain information from all image regions. However, when resizing like
this, the degree of distortion for each image varies based on the original size, and thus the model has to process different distortions and
the distorted proportions these entail.

/Cropping out/ the middle part of the image and padding with black if the
image's height or size is smaller than 224 pixels. One drawback with this method
is that if we were to exclude an essential part of the image, there would be no
information for the model to refer to. Furthermore, since the padded values are
all 0's, they result in wasted computation, thus inefficient training.

/Randomly cropping out/ a part of the image with the desired size. This method
has the same problem as the second approach, however by cropping out a random
part, rather than just the center, we can input the Neural Network a
wider variety of images, since even if we use the same image twice, there is a
high probability that the images are cropped differently.

Figure [[fig:floorplan_transforms]] shows how different techniques influence the
different cropping methods and let us observe some of the problems outlined.
The first row shows the distorted images. All the images with the label
7.7 look highly alike and are actually from the same building. However, while
the first and eighth picture images look highly alike, the ninth
does not because the original image contains more white on either side. Even
though the layout looks a lot alike, the resized image looks different. In
the second row, we can see that the compass rose of the pictures labeled 8.0 and
8.57 is cropped out. In their squished versions, however, it is included. In the
last row, see the random crop method for the floorplan in the first column of the
other rows. While we get most of the details, with the correct proportions,
due to the random nature of our cropping, we do not have any image containing the apartment's balcony. The third approach yielded the best results in
some preliminary experiments. Thus all results are reported using this "Random
Crop" strategy.

#+name: fig:floorplan_transforms
#+label: fig:floorplan_transforms
#+CAPTION: This figure showcases the properties of each resizing method. The first and second row show the same floorplans, the third shows different crops of the leftmost floorplan of the above two rows.
#+ATTR_LATEX: :name fig:floorplan_transforms :label fig:floorplan_transforms :width 15cm
[[file:./assets/resizes.jpg]]

** Hedonic Price estimation
The hedonic price estimation is done via a Multiple log-linear regression model
using all variables collected and outlined in [[tab:var_explanation]]. We
log-transform the target variable of apartment rent. While preliminary tests of
our model did only showed a slight improvement in $R^{2}$, the Neural network
improved significantly. Furthermore, many of the research papers cited in this
paper use log-transformed rents as well, so we will side with convention.
We created dummy matrices for each of our categorical variables,
ending up with 724 columns, including the intercept column. The "station"
variable's cardinality of 684, and the "style" variable's cardinality of 31
caused this significant increase in dimension. Furthermore, we added a squared term
for the "Time to station" variable to the design matrix.
We estimated three different models, one using all variables, without the rent
prediction of the Neural Network, one using all variables with the rent
prediction of the neural network, using only the neural network and an intercept.


* Results
In this section, we will look at the results of the proposed method. Firstly, we
will look at the results quantitatively, and afterward, we will take a look at the
models and their predictions qualitatively by looking at some examples and
edge cases to better understand how the predictions work and how the model makes
its predictions.

** Quantitative
Table [[tab:regression]] shows the results for three models described in [[Hedonic
Price estimation]]. The first column shows the estimated coefficients and standard
errors, without the predictions obtained from the neural network (Hereafter
sometimes referred to as NN Factor), the second shows the estimated coefficients
with the predictions, and the last shows the values for the model with intercept
and the predictions of the neural network only. We included all categorical
variables in both of the first two regressions, but did not include their
coefficients in the table due to their high cardinality.
#+NAME: tab:regression
#+LABEL: tab:regression
#+ATTR_LATEX: :label tab:regression :name tab:regression
#+INCLUDE: "assets/table2.tex" export latex
Looking at this table, we observe a considerable increase in the explanatory power of the model using the NN's predictions over the one that does not include the NN's predictions. The \( R^{2} \) value moves from
0.915, to 0.945, and the Residual Std. Error is reduced from 0.127 to 0.101,
a reduction in error of \( \approx 20\% \). The signs of the coefficients in the models are as
one would expect them to be and do not change with the inclusion of the Neural network prediction.
However, the magnitude of the coefficients moved toward 0 in every case.
Furthermore, the previously non-significant factor of "Admin fee" became
significant after the inclusion of the new feature. A similar pattern holds for the variables
included in the regression but not in this table. Most
of these coefficients moved toward 0, neither changing sign nor significance.

Figure [[fig:corrplot]] Shows a correlation plot of all of the variables, many of the
explanatory variables are quite highly correlated, which means that it becomes
hard to interpret the model, and might be an opportunity for improvement in
future works.

#+NAME: fig:corrplot
#+LABEL: fig:corrplot
#+ATTR_LATEX: :label fig:corrplot :name fig:corrplot :width 8cm
#+CAPTION: Heatmap showing the correlations of the variables displayed in [[tab:regression]].
[[./assets/corrplot.png]]


** Qualitative

Next, we would like to look at our models' predictions more qualitatively. In figure [[fig:residual_plots]] we plotted the predictions against
their actual values to try and see whether there are any patterns of
mispredictions in our models. We can see that all of our models seem to
overpredict the most expensive properties. In [[fig:residual_plots]] we drew a
dotted line at \(x=log(100) \approx 4.6\). After this point, all models seem
to overpredict the rent prices greatly. While the linear models have few
but very high over-predictions, the Neural Network's residuals are smaller
but have shifted systematically. The reason for the relatively low
residuals of the Neural network is that we used scaled its predictions with
the sigmoid layer discussed in [[Models, Methods, Architecture]]. Furthermore,
the neural network underpredicts many low rent properties, possibly
because, in some of these cases, the properties have a good location, to which
they owe their higher prices.
#+LABEL: fig:residual_plots
#+NAME: fig:residual_plots
#+ATTR_LATEX: :height 4cm :label fig:residual_plots :name fig:residual_plots
#+CAPTION: This image shows the residuals of the predictions of the two models and the Neural network. The x and y axes for all of the plots are the same. The dotted blue line is drawn at \( x = log(100) \approx 4.6 \).
[[./assets/residual_plot.png]]

Next, we would like to examine some predictions of the models in even more
detail.
We will look at the following patterns of predictions.

1. Some random predictions
2. The highest and lowest predictions of the network
3. The predictions that were the most due to input of the Neural Network
4. Predictions for properties with similar characteristics but whose value considerably changed due to the Neural network predictions.

Firstly, we will look at some randomly extracted images in figure
[[fig:random_examples]]. We show these predictions mostly to showcase the available
floorplans and the targets. The Neural network is not radically off with any
prediction in this example, with the highest difference in prediction and price
being 17000¥. However, it is hard to tell exactly why the Neural Network made
the predictions it did. Some of the more extreme predictions are more easily
discernible patterns. Some of these more extreme predictions are due to problems
with the dataset. However, they also seem to give us some insight into how the
Neural Network is making its predictions, so instead of removing these cases and
retraining the model right away, we decided to still explore them in this
section.

#+LABEL: fig:random_examples
#+NAME: fig:random_examples
#+ATTR_LATEX: :height 4cm :label fig:random_examples :name fig:random_examples
#+CAPTION: This image shows the NN's predictions and ground truths for a randomly extracted sample of the dataset. The units are in 10,000¥.
[[./assets/random_table.png]]

Moving onto more extreme cases, we tried looking at the highest and lowest
predictions in Figures [[fig:negtop]] and [[fig:postop]]. Here we show images that the Neural
Network's predictions were the lowest and highest for.
#+LABEL: fig:negtop
#+NAME: fig:negtop
#+ATTR_LATEX: :label fig:negtop :name fig:negtop :height 4cm
#+CAPTION: These are the four predictions the model predicted the lowest rent for.
[[./assets/rand_neg_top_100.png]]
The floorplans for figure [[fig:negtop]] are solely for dormitory or boarding house-like
apartments. The model seems to have picked up on the repetitive pattern in the floorplan
often present in these apartments.
Although the overall size is of the floors is quite extensive, and the floorplan spans multiple floors. The model's predictions seem to be at least aware that only a single room is considered.
However, as we see later in the leftmost picture of figure [[fig:upward]], the model cannot correctly tell these kinds of shared-living spaces from big apartments intended for a single household.
Note that the predictions for the middle two floorplans were different even though the floorplans are the same. This is due to the preprocessing step where we randomly crop our images. When making the two predictions for the middle floorplans, the model thus had slightly different inputs and outputs. This image appears twice in the dataset because
two different rooms in this building were open for rent, which explains the difference in actual prices.

#+LABEL: fig:postop
#+NAME: fig:postop
#+ATTR_LATEX: :label fig:postop :name fig:postop :height 4cm
#+CAPTION: The floorplans of the four apartments with the highest predicted rents.
[[./assets/rand_top_100.png]]
Moving onto the highest predictions of the Neural network, in figure [[fig:postop]] we see that the Networks residuals are much higher.
The model seems to choose spacious apartments with multiple floors, prominent balconies
and a non-repetitive layout for its highest predictions.
Overall, however, it is harder to find a definitive pattern in the highest predictions of the model.

#+LABEL: fig:downward
#+NAME: fig:downward
#+ATTR_LATEX: :height 4cm :label fig:downward :name fig:downward
#+CAPTION: This image shows the floorplans of the apartments with the biggest decreases in prediction after considering Neural Network output.
[[./assets/overpreds.png]]
Figure [[fig:downward]] and [[fig:upward]] have a slight change
in format. In these Figures, we compare the differences in the predictions of
Models 1 and 2 for a given apartment, to find the observations where the
Neural Network prediction had the largest impacts. These predictions were
performed using all available variables. Furthermore, we display the floorplans
and the Neural Network's predictions. Figure [[fig:downward]] shows the greatest
downward shifts due to the Neural Network predictions. Here, we again have the
problem of the same picture being present multiple times. The property with the
middle floorplan was posted to the website under different names by different
agencies multiple times, even with different prices. It is quite large
with a nice location, which is why the Linear Models
overestimate it so largely. Another reason for this big performance difference is
that while we are scaling the Neural Networks predictions, we are not doing
anything the like for the Linear Model. In the rightmost picture, we can see
that the model's prediction was far below the property's actual value,
while the linear model's predictions were much closer to the actual value. This
seems to be due to the simplistic layout of the property. Upon further
investigation, it also turned out that his property is an office space
that was mistakenly posted on the wrong part of the website.

Finally, we will look at the greatest upward movements after considering the
predictions of the neural network.
#+LABEL: fig:upward
#+NAME: fig:upward
#+ATTR_LATEX: :height 4cm :label fig:upward :name fig:upward
#+CAPTION: The floorplans of the apartments with the biggest increases in predicted rent due to the Neural Network input.
[[./assets/underpreds.png]]
The first floorplan was posted for a room available in a
shared flat, and for this property, the first model's predictions are much more
accurate than the other two predictions. This is because the Neural Network
overpredicted the rent by a lot. The reason for this seems to be that the
The neural network was considering the floorplan as a whole, while the actual
apartment that was up for rent is only a single room in the floor plan. A
similar problem most likely occurred with the third floorplan, which displays the
apartment's floorplan and a balcony that everyone living in the
apartment seems to be able to use.


* Discussion
Some of our results are hard to interpret, e.g., multimodal learning is worse
than the ensembling method. (probably) Why?
** Problems of very high dimensionality due to many categories in the categorical variables.
** The Neural Network seems to be very positive with its predictions; is there something we can do about it?
** We only have a minimal amount of variables about the actual apartments. Having more variables about the apartment should/will probably remove some of the explanatory of the CNN
Many studies in the actual literature use much bigger datasets, both column and row-wise, and we believe that the inclusion of more variables used would
reduce the explanatory power of the model proposed in the current paper. For
example, different datasets might have a column for the number of bathrooms a
given property has. Should this turn out to be a significant variable,
the explanatory power of our Neural network in the final hedonic price model will
probably decrease. However, we believe that our model still has some practical
advantages because obtaining floorplans is often much more manageable than tabular
data for a large number of apartments.

** Further possible investigations
*** Looking into what the model focuses on when making predictions
*** Furthermore, we only have the Tokyo Rental apartment market, including other markets that might be interesting
*** Looking into rented apartments would be interesting.
*** Comparing our results with consumers opinions might be interesting

* Conclusion
Overall, we used real estate data collected from a publicly available website,
to train a Residual based Convolutional Neural Network for prediction of rent
prices based solely on that properties' floorplan. We also showcased some tweaks
to enhance the original model, to allow for quicker training and
convergence. We showed that it is possible to effectively leverage floorplan
image information to prediction rent prices, and that these predictions can
enhance other more traditional models' predictive power. While we did not have any
access to very detailed information about the apartments themselves, and thus
were not able to test the effectiveness of floorplan image analysis against,
models making use of more tabular data, we believe that using floorplan data
could be an option for entities trying to estimate rent prices,
without the need for interviewing participants. Our results seem to be inline
with existing literature on the topic of real-estate value composition, however
we believe that this paper shows initial evidence that is using Computer vision for
some instances of rent prediction might be more practical than traditional, manual ways o feature collection.


\printbibliography

* Footnotes

[fn:2] They use the word 基礎環境, referring to items such as ventilation, lighting or insulation.
[fn:1] The way to interpret these layouts is as follows: The Number at the
beginning denotes the number of bedrooms. Following that, come the letters "S",
"L", "D" and "K", which stand for "Service", "Living", "Dining" and "Kitchen."
respectively. Thus a "2LDK" apartment would have two bedrooms, one living room, one
dining room, and one kitchen. Service often stands for a small room without enough
lighting or ventilation to count as a bedroom. These rooms are often utilized
for storage. In figure [[fig:hists]], 1R stands for ワンルーム(1 Room), a layout in
which there either is no Kitchen, or there is no partition between the kitchen
and the bedroom.
