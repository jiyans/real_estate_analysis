# -*- org-latex-pdf-process: ("latexmk -shell-escape -pdfdvi -synctex=1 -latex=platex %f "); -*-
#+TITLE: Incremental informational value of floorplans for rent price prediction
#+SUBTITLE: Applications of modern computer vision techniques in real-estate
#+EMAIL:     jiyan.schneider@keio.jp
#+DATE:      2022-02-28
#+LATEX_CLASS: jarticle
#+latex_class_options: [twocolumn]
#+OPTIONS: toc:nil email:nil author:nil title:nil H:4 num:nil
#+LATEX_HEADER: \usepackage{jsaiac}
#+LATEX_HEADER: \author{\ename{Jiyan Schneider\first \second} \and \ename{Takahiro Hoshino\first \second}}
#+LATEX_HEADER: \affiliate{\ename{\first{}Graduate School of Economics, Keio University} \and \ename{\second{}AIP Center, RIKEN}}
#+BIBLIOGRAPHY: ./local-bib.bib

#+begin_abstract
This study strives to examine whether consideration of floorplan images of
real-estate apartments could effectively improve real-estate rental price
predictions. We use a modern computer vision technique to predict the
rental price of apartments using the floorplan of the apartment exclusively.
Afterward, we use these predictions combined with a more traditional
hedonic pricing method to see whether its predictions improved. We found that
by including the predictions, we were able to increase the accuracy of the
predictions from an \( R^{2} \) of 0.915 to an \( R^{2} \) of 0.945. This improvement
suggests that floorplans contain considerable information about rent
prices, not captured in the other explanatory variables used. Further
investigation, including more explanatory variables about the apartment itself,
could be used in future research to further examine the price structure of real
estate and better understand consumer behavior.
#+end_abstract

\maketitle

* Introduction
The problem of real estate value estimation comes up frequently in society, and
many agents have incentives for an accurate prediction. Furthermore, we believe
that if it is possible to apply computer vision methods to real estate, it might
open up avenues for further studies into consumer behavior and the structure of
real-estate prices in the future.

The underlying hypothesis of our research is that the floorplans contain
characteristics that are valuable to consumers but are neglected with
traditional methods of price estimation. Furthermore, we hypothesize that it is possible to leverage these factors by utilizing deep learning. We collected tabular data and floorplans of over 140,000 rental apartments in
the Tokyo Metropolitan area. Then we devised some minor changes to a widely used
neural network architecture and trained a neural network (NN hereafter) to
predict the rent of an apartment given only its floorplan. Finally, we combined
the NN's prediction with a traditional hedonic regression model and analyzed the
effects of including the NN's predictions.

Doing this, we find that the neural network can explain a considerable
proportion of the rent price of many real-estate properties and considerably
improve the explanatory power of the hedonic regression model.

One of the main reasons that the floorplans might contain previously
untapped potential is that studies in real-estate economics tend to find that
so-called "structural" features have more significance in the consumers' eyes
than so-called "environmental" ones. [cite:@choi2003;@akiyama_yuki2019320204]

* Methodology
** Data
The dataset used is a mix of tabular and image data of rental real estate
properties listed on a public website from the Tokyo Metropolitan area. The data
was collected by the authors to write this paper. The dataset used has over
140,000 observations, three categorical and seven continuous variables, including
the target variable. As this is primarily an exploratory report, we limited our
dataset to the Tokyo Metropolitan area to sidestep the problem of having to
consider multiple markets.
The categorical and continuous variables are characteristics describing either
the building of an apartment or the apartment itself, such as Apartment size, Number
of floors, or the name of the closest train station.

** Neural Network Architecture
For the construction of the Neural Network, we relied on the software libraries
~fastai~ [cite:@howard20_fastai], ~pytorch~ and ~torchvision~. (Pytorch and
torchvision both by the PyTorch team [cite:@NEURIPS2019_9015]). We built on the
~resnet50~ implementation by [cite:@NEURIPS2019_9015] of the model outlined in
[cite:@he15:deep_resid_learn_image_recog]. We initialized the model's weights
to the pre-trained weights available in ~torchvision~. These weights are trained
using the "ImageNet" [cite:@imagenet2009] dataset.

We replaced the last layers with a custom adaptation to better fit the
regression task at hand. We used the same base model up until the first fully
connected layer, after which we replaced all layers with a custom head.
We found that when using a simple fully-connected network, the model would sometimes make exceedingly high
predictions, which complicated the model training by abnormally increasing the
loss, resulting in exploding gradients. Thus, we decided to modify the final
layer to scale the Neural Network's output between a predetermined range. The
last layers were scaled with a sigmoid function. By scaling the outputs of the
neural network, we could prevent these problems at the expense of introducing
one hyperparameter, they-range. To decide on the y-range for our neural
network, we used the log-transformed target variable's greatest lower and least
upper integer bounds. Since the extreme values were 0.095, and 5.521, we chose 0
and 6 as our bounds. This layer scales the output vector from the Network
elementwise according to the following rule. \(s(x) = \sigma(x) (hl) + l \),
where \( \sigma(x) = \frac{1}{1+e^{-x}} \), \( l \) is the lower bound, and \( h
\) is the upper bound. The outputs of this function are then used to calculate
the loss, ensuring that initial predictions of the network are never
unreasonably high, ultimately resulting in easier training and convergence.

We used the mean squared error as a loss function, and before training the whole
model, we froze the base model and trained the custom head only. After initial
rounds of training the head only, we "unfroze" the pre-trained weights and
trained the whole neural network. The model was optimized with Adam
[cite:@kingma2017adam], and the learning rate schedule an initial learning rate
was chosen as suggested in
[cite:@smith17_cyclic_learn_rates_train_neural_networ].

** Hedonic Price Estimation
The hedonic price estimation was performed via a multiple linear regression
model using all variables collected. We log-transform the target variable of
apartment rent. We created dummy matrices for each of our categorical variables,
ending up with 724 columns, including the intercept and continuous columns. The
"station" variable's cardinality of 684 and the "Style" variable's cardinality
of 31 caused this significant increase in dimension. Furthermore, we added a
squared term for the "Time to station" variable to the design matrix.

* Results
We estimated three different models, one using all variables, without the rent
prediction of the Neural Network, one using all variables with the rent
prediction of the neural network, using only the neural network and an
intercept. Table [[tab:regression]] shows the results for these three models on
different parts of the dataset. We performed an 80-to-20 train-to-test split based on
the buildings, not apartments, to avoid information leakage.
#+NAME: tab:regression
#+LABEL: tab:regression
#+CAPTION: \( R^2 \) and sample size for the three models obtained on different parts of the dataset.
#+ATTR_LATEX: :label tab:regression :name tab:regression
|------------------------+---------+---------+--------|
|                        |   total |   train |   test |
|------------------------+---------+---------+--------|
| \( R^{2} \) Without NN |   0.915 |   0.915 |  0.914 |
| \( R^{2} \) With NN    |   0.945 |   0.951 |  0.923 |
| \( R^{2} \) Only NN    |   0.897 |   0.917 |  0.817 |
| N                      | 141,394 | 113,116 | 28,278 |
|------------------------+---------+---------+--------|
We observe a considerable increase in the model's predictive power using the
NN's predictions over the one that does not include the NN's predictions. We can
see that the \(R^{2} \) value improves after including the predictions from the
NN, from 0.915 to 0.945, on the total dataset, and 0.914 to 0.923 on the
test data set. The residual standard error on the total dataset was reduced from
0.127 to 0.101, a reduction in error of \( approx 20\% \).

* Discussion

We suppose that the reasons for the effectiveness of the neural network are as follows: Firstly, by using the floorplans, the neural network had access to
information that influences rent and residential satisfaction [cite:@choi2003]
of a particular real estate. Thus, it can find features that affect rent that
are not available in the tabular dataset and leverage them for prediction.
However, the increase in explanatory power partly also stems from the simplicity of
our dataset. While we had a sizable amount of apartments and floorplans, we had
fewer explanatory variables than other studies on hedonic pricing of real-estate rent prediction. Furthermore, we only used apartments from the Tokyo Metropolitan area.

We presume that by using more variables about the apartments' structural
features, the regression models' predictive power would increase, and the
influence of the NN in the same model would decrease. Moreover, because we
only included information from the Tokyo metropolitan area, the
discrepancies in rent based solely on the location were comparatively small.
This study was exploratory only, and further investigation might include how to
deal with the problem of different markets.

* Conclusion
We used publicly available real estate data to train a residual-based
convolutional neural network to predict rent prices based solely on that
properties' floorplan. We proposed some tweaks to enhance the original model to
allow for quicker training and convergence for our case of real-estate
prediction. We showed that it is possible to effectively leverage floorplan
images to improve the prediction of rent prices and that these predictions can
enhance other more traditional models' predictive power. We only had limited
access to detailed information at the apartment level. We thus could not test
the effectiveness of floorplan image analysis against models using a
wider variety of tabular data. We suspect that using floorplan data could be an
option for entities trying to estimate rent prices without the need for
interviewing participants or employing other costly means of gaining
apartment-level information. Our results seem to be in line with existing
literature on the topic of real-estate price composition. Lastly, we believe
that this paper shows initial evidence that using computer vision for rent
prediction, especially in low data-availability situations, can be practical.

\printbibliography
