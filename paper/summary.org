#+title: [SUMMARY] Using Deep Learning to Assist Modelling of Tokyo Real Estate Prices
#+SUBTITLE: An evaluation of an incorporation of deep learning methods for prediction real estate prices
#+AUTHOR: Jiyan Jonas Schneider
#+DATE: 2021-12-20
#+LATEX_HEADER: \usepackage{xeCJK}
#+BIBLIOGRAPHY: /Users/jiyanschneider/Dropbox/Documents/lib/bibliography/bibliography.bib
#+LATEX_HEADER: \setCJKmainfont{HiraginoSans-W3}
#+LATEX_HEADER: \usepackage[backend=biber, style=apa]{biblatex}
#+LATEX_HEADER: \setmainfont{EBGaramond-Regular}
#+LATEX_HEADER: \usepackage[a4paper,left=2.5cm,right=2.5cm,top=2.5cm,bottom=2.5cm]{geometry}
#+LATEX_HEADER: \usepackage{graphics}
#+LATEX_HEADER: \usepackage{rotating}
#+LATEX_HEADER: \usepackage[doublespacing]{setspace}
#+LATEX_CLASS_OPTIONS: [11pt,titlepage]
#+OPTIONS: toc:nil H:4


#+begin_abstract
This study strives to examine whether consideration of floorplan images of
real-estate apartments could be effective for improving real-estate rental price
predictions. We use a modern computer vision technique to predict the
rental price of apartments using the floorplan of the apartment exclusively.
Afterward, we use these predictions combined with a more traditional
hedonic pricing method to see whether its predictions improved. We found that
by including the predictions, we were able to increase the accuracy of the
predictions from an \( R^{2} \) of 0.915 to an \( R^{2} \) of 0.945. This
suggests that floorplans contain considerable information about rent
prices, not captured in the other explanatory variables used. Further
investigation, including more explanatory variables about the apartment itself,
could be used in future research to examine the price structure of real
estate further and better understand consumer behavior.
#+end_abstract

* Introduction
In our paper, we look into the problem of real estate rental price estimation,
and in how far it is possible to apply computer vision toward it. The reason
why we do so is because the problem of real estate value estimation comes up
often times in society, and many agents have incentives for an accurate prediction.
Furthermore, we believe that if it is possible to apply computer vision methods
to real-estate, it might open up venues for further studies into consumer behavior
and the structure of real-estate prices in the future.

The underlying hypothesis of the research paper is that the floorplans contain
characteristics that are valuable to consumers, but are neglected
with traditional methods. Furthemore, we hypothesize that some of these factors
could be leveraged with deep learning. In the long run, we hope to advance
insight into the price structure of real estate and consumer behavior
surrounding real estate using such methods.

To test our hypothesis, we first collected tabular data and floorplans of over
140,000 rental apartments in the Tokyo Metropolitan area from a publicly
available website. Then we devised some minor changes to a widely used neural
network architecture and trained a neural network (NN hereafter) to predict the
rent of an apartment given only its floorplan. Finally, we combined the NN's
prediction with a traditional hedonic regression model and analyzed the effects
of including the NN's predictions.

Doing this, we find that the neural network can explain a considerable
proportion of the rent price of many real-estate properties and considerably
improve the explanatory power of the hedonic regression model. Including the
neural network does not overly take away explanatory power from variables that
would be considered important in a more traditional model or affect the other
variables in other unexpected ways, showing that the NN captures at least some
previously unconsidered factors.

One of the main reasons, we think that the floorplans might contain
previously untapped potential, is that economics studies tend to find that
so-called "structural" features have more significance in the consumers' eyes
than so-called "environmental" ones. [cite:@choi2003;@akiyamayuki2019230204]
In the complete paper we discuss these sources in more detail, and also present some
other previous attempts of using computer vision models in real-estate estimation.

* Methodology
** Data
The dataset used is a mix of tabular and image data of rental real estate
properties listed on a public website from the Tokyo Metropolitan area. The data
was collected by the author to write this paper. The dataset we are using has
over 140,000 observations, but only 3 categorical and 7 continuous variables
including the target variable. THus we have more observations, but less
categories than in most papers the author reviewed. We focused on rental
apartments in Tokyo in particular because, as outlined in
textcite:moriizumi1986,weko_55303_1 and textcite:akiyama_yuki2019320204,
estimating real estate prices throughout different markets are more challenging
and causes complications. This paper is primarily an exploratory study, so we
decided that by focusing on "roughly" a single market, we can sidestep the
problem of considering multiple markets and focus on the viability of these
computer vision methods first. For each listing, we have the monthly rent of the
apartment, the image of the floorplan of the apartment, 6 continuous and 3
categorical variables. The details for the tabular variables are described in
Table [[tab:var_explanation]].
#+LABEL: tab:var_explanation
#+NAME: tab:var_explanation
#+CAPTION: Explanation of the variables collected and used in this study.
#+ATTR_LATEX: :name tab:var_explanation :label tab:var_explanation
|------------------------+-----------------------------------------------------------------|
| Variable               | Explanation                                                     |
|------------------------+-----------------------------------------------------------------|
|------------------------+-----------------------------------------------------------------|
| Apt. Floor             | The floor the property is on property                           |
| Size in \( m^2 \)      | Size of property in $m^2$                                       |
| Time to station        | No. minutes of taking "method" to the next station              |
| Age bldg.              | No. of years ago the property was built                         |
| No Floors bldg         | No of floors of the building                                    |
| Admin fee \(10,000 Â¥\) | Amount of monthly administration fee                            |
|------------------------+-----------------------------------------------------------------|
| Station                | Name of the closest public transport station                    |
| Method                 | How "Time to station" is measured (foot, bus, or car)           |
| Style                  | Description of the layout type of the apartment (1K, 1LDK,... ) |
|------------------------+-----------------------------------------------------------------|
| apt_rent               | Rent per month of the listing. In units of 10000 Yen            |
|------------------------+-----------------------------------------------------------------|

** Neural Network architecture
For the construction of the Neural Network, we relied on the software libraries
~fastai~ [cite:@howard20_fastai], ~pytorch~ and ~torchvision~. (Pytorch and
torchvision both by the PyTorch team [cite:@NEURIPS2019_9015]). We built on the
~resnet50~ implementation by textcite:NEURIPS2019_9015 of the model outlined in
textcite:he15:deep_resid_learn_image_recog. We initialized the model's weights
to the pre-trained weights available in ~torchvision~. These weights are trained
using the "ImageNet" [cite:@imagenet2009] dataset.

We replaced the last layers with a custom adaptation to better fit the
regression task at hand. We used the same base model up until the first fully
connected layer, after which we replaced all layers with a custom head.
Initially, we used a fully connected layer with a single output as the final
layer. However, we found that sometimes the model would make unreasonably high
predictions, which complicated the model training by abnormally increasing the
loss, resulting in "exploding gradients". Thus, we decided to add another layer
to scale the Neural Networks output between a predetermined range. In
particular, we scaled the last layer's outputs with a sigmoid function. By
scaling the outputs of the neural network, we could prevent these problems at
the expense of introducing one hyperparameter, the y-range. To decide on the
y-range for our neural network, we used the log-transformed target variable's
greatest lower and least upper integer bounds. Since the extreme values were
0.095, and 5.521, we chose 0 and 6 as our bounds. This layer scales the output
vector from the Network elementwise according to the following rule. \(s(x) =
\sigma(x) (hl) + l \), where \( \sigma(x) = \frac{1}{1+e^{-x}} \), \( l \) is
the lower bound, and \( h \) is the upper bound. The outputs of this function
are then used to calculate the loss, ensuring that initial predictions of the
network are never unreasonably high, ultimately resulting in easier training and
convergence.

We used the mean squared error as a loss function, and before training the whole
model, we "froze" the base model and trained our custom head only. After
initial rounds of training the head only, we "unfroze" the pre-trained weights
and trained the whole neural network. The Resnet model was optimized with Adam
[cite:@kingma2017adam], and the learning rate schedule an initial learning rate
was chosen as suggested in
textcite:smith17_cyclic_learn_rates_train_neural_networ.

** Hedonic Price estimation
The hedonic price estimation was performed via a multiple linear regression
model using all variables collected. We log-transform the target variable of
apartment rent. While preliminary tests of the multiple regression model only
showed a slight improvement in $R^{2}$, the NN's predictions improved
significantly. We created dummy matrices for each of our categorical variables,
ending up with 724 columns, including the intercept and continuous columns. The
"station" variable's cardinality of 684 and the "Style" variable's cardinality
of 31 caused this significant increase in dimension. Furthermore, we added a
squared term for the "Time to station." variable to the design matrix. We
estimated three different models, one using all variables, without the rent
prediction of the Neural Network, one using all variables with the rent
prediction of the neural network, using only the neural network and an
intercept.

* Results
Table [[tab:regression]] shows the results for three models described in [[Hedonic
Price estimation]]. The first column shows the estimated coefficients and standard
errors, without the predictions obtained from the neural network (hereafter
referred to as NN Factor), the second shows the estimated coefficients with the
predictions and the last shows the values for a Linear Regression model with
intercept and the predictions of the neural network only. We included all
categorical variables in both of the first two regressions, but did not include
their coefficients in the table due to their high cardinality.
#+NAME: tab:regression
#+LABEL: tab:regression
#+ATTR_LATEX: :label tab:regression :name tab:regression
#+INCLUDE: "assets/table2.tex" export latex
We observe a considerable increase in the model's predictive power using the
NN's predictions over the one that does not include the NN's predictions. The \(
R^{2} \) value moves from 0.915, to 0.945, and the residual standard error is
reduced from 0.127 to 0.101, a reduction in error of \( \approx 20\% \). The
signs of the coefficients in the models are as one would expect and do not
change with the inclusion of the Neural network prediction. The magnitude of the
coefficients moved toward 0 in every case. Moreover, the previously
non-significant factor of "Admin fee" became significant after the inclusion of
the new feature. A similar pattern holds for the variables not included in the
table. Most of these coefficients moved toward 0, neither changing sign nor
significance.

* Discussion
Our discussion section consists of two parts. The first part discusses the
predictions of the models, the shortcomings of the models, and some potential
remedies. The second part discusses the overall results of our paper in a general
sense. In the paper, more examples for the model's predictions are given, however,
for the sake of brevity, we only show a single example in this summary.

For this example we will look at the greatest upward movements due to the predictions of the
neural network.
#+LABEL: fig:upward
#+NAME: fig:upward
#+ATTR_LATEX: :height 4cm :label fig:upward :name fig:upward
#+CAPTION: The floorplans of the apartments with the biggest increases in predicted rent due to the Neural Network's prediction.
[[./assets/underpreds.png]]

The first floorplan in figure [[fig:upward]] is a floorplan for a shared flat, and
it depicts all private rooms, as well as the public rooms everyone living there
may use. For this realestate property, the prediction of the first model much
more accurate than the other two. This is because the neural network
overestimated the rent by a lot. The reason for the NN's overestimation might be
that the neural network was considering the floorplan as a whole, while the
actual apartment available for rent is only a single room. A similar problem
seems to have occurred with the third floorplan, which displays the apartment's
floorplan and a balcony that everyone living in the building can use. The
reasons for the high upward shift in the second and fourth floorplans are much
harder to discern. The problem of the first and third images described above, is
correctly handled in some other images further outlined in the main paper.

We suppose that the reason for the effectiveness of the neural network is twofold:
1. By using the floorplans, the neural network had access to information that
   influences rent and residential satisfaction [cite:@choi2003] of a particular
   real estate. Thus it can find features that influence rent that are not
   available in the tabular dataset, and leverage these for its prediction.
2. The increase in explanatory power seems extraordinarily high because of our
   relatively simple dataset. While we had a sizable amount of apartments and
   floorplans, we had much fewer explanatory variables than other studies on
   hedonic pricing. Furthermore, we only had apartments from the Tokyo
   Metropolitan area.
To further expand on the second point, most studies we reviewed made use of many
more explanatory variables, especially about structural features of the
apartments. We presume that by using more variables, the regression models'
predictive power would increase, and the weight of the NN in the same model
would decrease. However, in situations where it might be easier to obtain
floorplans of apartments rather than the tabular data of the categorical
features, an approach utilizing computer vision might be worth considering. So
our method could be used by entities who do not have the resources to gather a
dataset of tabular features but could obtain the floorplans.

This study was exploratory only, and further investigation might include how this
method fares with floorplans in different markets. The current dataset only
includes a limited area of rental apartments in and around Tokyo. This, however,
means that the rent prices we encountered did not deviate as much as they would
when considering more markets. We can easily imagine that bigger discrepancies
in rent amount due to location only could disturb our model. The same problem,
less pronounced, is present in the current dataset already because apartments
with mostly the same layout in different locations will have different prices.
One potential remedy for this problem could be training the model on the
residuals of a multiple linear regression controlling for location. Doing this,
it might be possible to reduce some of the effects of location on rent.

Another problem with Neural networks, in general, is that they are hard to
interpret, which also applies to the current study. We have trouble explaining
why the model is making some of its predictions. textcite:NIPS2017_7062, for
example, provide an approach for general black-box model interpretation, which
has also applied to computer vision. Analyzing the current model using
the technique outlined there might give us more insight into its internals and
observe its focus when making predictions. This, in turn, might lead to insights
into consumer behavior.

* Conclusion
We used real estate data collected from a publicly available website to train a
residual-based convolutional neural network to predict rent prices based
solely on that properties' floorplan. We proposed some tweaks to enhance the
original model to allow for quicker training and convergence in the case of
real-estate prediction. We showed that it is possible to effectively leverage
floorplan image information to improve the prediction of rent prices and that these
predictions can enhance other more traditional models' predictive power. We only
had limited access to detailed information at the apartment level and thus could not test the effectiveness of floorplan image analysis against models
making use of a wider variety of tabular data. We suspect that using floorplan
data could be an option for entities trying to estimate rent prices without the
need for interviewing participants or employing other costly means of gaining
apartment-level information. Our results seem to be in line with existing
literature on the topic of real-estate price composition. Lastly, we believe
that this paper shows initial evidence that using computer vision for rent
prediction in low data-availability situations can be practical.

\printbibliography
